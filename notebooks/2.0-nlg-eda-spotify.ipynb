{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop #2 :\n",
    "## EDA - Spotify Tracks Dataset\n",
    "\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import logging\n",
    "\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from src.logging_config import setup_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.715</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>Ben Woodward</td>\n",
       "      <td>Ghost (Acoustic)</td>\n",
       "      <td>Ghost - Acoustic</td>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.267</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
       "      <td>Ingrid Michaelson;ZAYN</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.120</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n",
       "      <td>Kina Grannis</td>\n",
       "      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>\n",
       "      <td>Can't Help Falling In Love</td>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.143</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5vjLSffimiIP26QG5WcN2K</td>\n",
       "      <td>Chord Overstreet</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.167</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                track_id                 artists  \\\n",
       "0           0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
       "1           1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
       "2           2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
       "3           3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
       "4           4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Comedy   \n",
       "1                                   Ghost (Acoustic)   \n",
       "2                                     To Begin Again   \n",
       "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
       "4                                            Hold On   \n",
       "\n",
       "                   track_name  popularity  duration_ms  explicit  \\\n",
       "0                      Comedy          73       230666     False   \n",
       "1            Ghost - Acoustic          55       149610     False   \n",
       "2              To Begin Again          57       210826     False   \n",
       "3  Can't Help Falling In Love          71       201933     False   \n",
       "4                     Hold On          82       198853     False   \n",
       "\n",
       "   danceability  energy  ...  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.676  0.4610  ...    -6.746     0       0.1430        0.0322   \n",
       "1         0.420  0.1660  ...   -17.235     1       0.0763        0.9240   \n",
       "2         0.438  0.3590  ...    -9.734     1       0.0557        0.2100   \n",
       "3         0.266  0.0596  ...   -18.515     1       0.0363        0.9050   \n",
       "4         0.618  0.4430  ...    -9.681     1       0.0526        0.4690   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature  track_genre  \n",
       "0          0.000001    0.3580    0.715   87.917               4     acoustic  \n",
       "1          0.000006    0.1010    0.267   77.489               4     acoustic  \n",
       "2          0.000000    0.1170    0.120   76.332               4     acoustic  \n",
       "3          0.000071    0.1320    0.143  181.740               3     acoustic  \n",
       "4          0.000000    0.0829    0.167  119.949               4     acoustic  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the Spotify's dataset in the project directory\n",
    "csv_file = '../data/external/spotify_dataset.csv'\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview an Descriptive Statistics\n",
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of observations and features are obtained through Panda's `.shape` method. The \"Spotify\" dataset contains **114.000 observations (rows)** and **21 features (columns)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114000, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data types are obtained through Panda's `.dtypes` method. The Dataframe contains only 1 boolean feature, 5 object type features, 6 int64 type features and  9 float64 type features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 113549 entries, 0 to 113999\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   track_id          113549 non-null  object \n",
      " 1   artists           113549 non-null  object \n",
      " 2   album_name        113549 non-null  object \n",
      " 3   track_name        113549 non-null  object \n",
      " 4   popularity        113549 non-null  int64  \n",
      " 5   duration_ms       113549 non-null  int64  \n",
      " 6   explicit          113549 non-null  bool   \n",
      " 7   danceability      113549 non-null  float64\n",
      " 8   energy            113549 non-null  float64\n",
      " 9   key               113549 non-null  int64  \n",
      " 10  loudness          113549 non-null  float64\n",
      " 11  mode              113549 non-null  int64  \n",
      " 12  speechiness       113549 non-null  float64\n",
      " 13  acousticness      113549 non-null  float64\n",
      " 14  instrumentalness  113549 non-null  float64\n",
      " 15  liveness          113549 non-null  float64\n",
      " 16  valence           113549 non-null  float64\n",
      " 17  tempo             113549 non-null  float64\n",
      " 18  time_signature    113549 non-null  int64  \n",
      " 19  track_genre       113549 non-null  object \n",
      "dtypes: bool(1), float64(9), int64(5), object(5)\n",
      "memory usage: 21.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Unnamed: 0` column is dropped as it is not part of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The duplicated rows are obtained through Panda's `.duplicated` method. The Dataframe has 450 duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing values per feature are obtained through Panda's `.isnull().sum()` method. Only the features \"artists\", \"album_name\" and \"track_name\" have missing values, one missing value for each feature. This features, as indicated by their object datatype, are qualitative variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "track_id            0\n",
       "artists             1\n",
       "album_name          1\n",
       "track_name          1\n",
       "popularity          0\n",
       "duration_ms         0\n",
       "explicit            0\n",
       "danceability        0\n",
       "energy              0\n",
       "key                 0\n",
       "loudness            0\n",
       "mode                0\n",
       "speechiness         0\n",
       "acousticness        0\n",
       "instrumentalness    0\n",
       "liveness            0\n",
       "valence             0\n",
       "tempo               0\n",
       "time_signature      0\n",
       "track_genre         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows with null values are filtered  using the `.isnull()` method combined with `.any(axis=1)`. Only one row contains the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65900</th>\n",
       "      <td>1kR4gIb7nGxHPI3D2ifs59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.583</td>\n",
       "      <td>7</td>\n",
       "      <td>-9.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00396</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.734</td>\n",
       "      <td>138.391</td>\n",
       "      <td>4</td>\n",
       "      <td>k-pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     track_id artists album_name track_name  popularity  \\\n",
       "65900  1kR4gIb7nGxHPI3D2ifs59     NaN        NaN        NaN           0   \n",
       "\n",
       "       duration_ms  explicit  danceability  energy  key  loudness  mode  \\\n",
       "65900            0     False         0.501   0.583    7     -9.46     0   \n",
       "\n",
       "       speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "65900       0.0605          0.69           0.00396    0.0747    0.734   \n",
       "\n",
       "         tempo  time_signature track_genre  \n",
       "65900  138.391               4       k-pop  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_rows = df[df.isnull().any(axis=1)]\n",
    "\n",
    "filtered_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage of missing data is aproximmately 0.0001%, which in itself is not very significative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0001)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.isnull().sum().sum() / df.size * 100, 4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantitative variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive statistics of quantitative are generated through Panda's `.describe` method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>114000.000000</td>\n",
       "      <td>1.140000e+05</td>\n",
       "      <td>114000.000000</td>\n",
       "      <td>114000.000000</td>\n",
       "      <td>114000.000000</td>\n",
       "      <td>114000.000000</td>\n",
       "      <td>114000.000000</td>\n",
       "      <td>114000.000000</td>\n",
       "      <td>114000.000000</td>\n",
       "      <td>114000.000000</td>\n",
       "      <td>114000.000000</td>\n",
       "      <td>114000.000000</td>\n",
       "      <td>114000.000000</td>\n",
       "      <td>114000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.238535</td>\n",
       "      <td>2.280292e+05</td>\n",
       "      <td>0.566800</td>\n",
       "      <td>0.641383</td>\n",
       "      <td>5.309140</td>\n",
       "      <td>-8.258960</td>\n",
       "      <td>0.637553</td>\n",
       "      <td>0.084652</td>\n",
       "      <td>0.314910</td>\n",
       "      <td>0.156050</td>\n",
       "      <td>0.213553</td>\n",
       "      <td>0.474068</td>\n",
       "      <td>122.147837</td>\n",
       "      <td>3.904035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.305078</td>\n",
       "      <td>1.072977e+05</td>\n",
       "      <td>0.173542</td>\n",
       "      <td>0.251529</td>\n",
       "      <td>3.559987</td>\n",
       "      <td>5.029337</td>\n",
       "      <td>0.480709</td>\n",
       "      <td>0.105732</td>\n",
       "      <td>0.332523</td>\n",
       "      <td>0.309555</td>\n",
       "      <td>0.190378</td>\n",
       "      <td>0.259261</td>\n",
       "      <td>29.978197</td>\n",
       "      <td>0.432621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-49.531000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.740660e+05</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-10.013000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>99.218750</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>2.129060e+05</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-7.004000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>122.017000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.615060e+05</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-5.003000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.084500</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>0.683000</td>\n",
       "      <td>140.071000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.237295e+06</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.532000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>243.372000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          popularity   duration_ms   danceability         energy  \\\n",
       "count  114000.000000  1.140000e+05  114000.000000  114000.000000   \n",
       "mean       33.238535  2.280292e+05       0.566800       0.641383   \n",
       "std        22.305078  1.072977e+05       0.173542       0.251529   \n",
       "min         0.000000  0.000000e+00       0.000000       0.000000   \n",
       "25%        17.000000  1.740660e+05       0.456000       0.472000   \n",
       "50%        35.000000  2.129060e+05       0.580000       0.685000   \n",
       "75%        50.000000  2.615060e+05       0.695000       0.854000   \n",
       "max       100.000000  5.237295e+06       0.985000       1.000000   \n",
       "\n",
       "                 key       loudness           mode    speechiness  \\\n",
       "count  114000.000000  114000.000000  114000.000000  114000.000000   \n",
       "mean        5.309140      -8.258960       0.637553       0.084652   \n",
       "std         3.559987       5.029337       0.480709       0.105732   \n",
       "min         0.000000     -49.531000       0.000000       0.000000   \n",
       "25%         2.000000     -10.013000       0.000000       0.035900   \n",
       "50%         5.000000      -7.004000       1.000000       0.048900   \n",
       "75%         8.000000      -5.003000       1.000000       0.084500   \n",
       "max        11.000000       4.532000       1.000000       0.965000   \n",
       "\n",
       "        acousticness  instrumentalness       liveness        valence  \\\n",
       "count  114000.000000     114000.000000  114000.000000  114000.000000   \n",
       "mean        0.314910          0.156050       0.213553       0.474068   \n",
       "std         0.332523          0.309555       0.190378       0.259261   \n",
       "min         0.000000          0.000000       0.000000       0.000000   \n",
       "25%         0.016900          0.000000       0.098000       0.260000   \n",
       "50%         0.169000          0.000042       0.132000       0.464000   \n",
       "75%         0.598000          0.049000       0.273000       0.683000   \n",
       "max         0.996000          1.000000       1.000000       0.995000   \n",
       "\n",
       "               tempo  time_signature  \n",
       "count  114000.000000   114000.000000  \n",
       "mean      122.147837        3.904035  \n",
       "std        29.978197        0.432621  \n",
       "min         0.000000        0.000000  \n",
       "25%        99.218750        4.000000  \n",
       "50%       122.017000        4.000000  \n",
       "75%       140.071000        4.000000  \n",
       "max       243.372000        5.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualitative variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panda's `.describe` method is used with the parameter `include='object'` for describing all qualitative columns of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>114000</td>\n",
       "      <td>113999</td>\n",
       "      <td>113999</td>\n",
       "      <td>113999</td>\n",
       "      <td>114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>89741</td>\n",
       "      <td>31437</td>\n",
       "      <td>46589</td>\n",
       "      <td>73608</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>6S3JlDAGk3uu3NtZbPnuhS</td>\n",
       "      <td>The Beatles</td>\n",
       "      <td>Alternative Christmas 2022</td>\n",
       "      <td>Run Rudolph Run</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>9</td>\n",
       "      <td>279</td>\n",
       "      <td>195</td>\n",
       "      <td>151</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      track_id      artists                  album_name  \\\n",
       "count                   114000       113999                      113999   \n",
       "unique                   89741        31437                       46589   \n",
       "top     6S3JlDAGk3uu3NtZbPnuhS  The Beatles  Alternative Christmas 2022   \n",
       "freq                         9          279                         195   \n",
       "\n",
       "             track_name track_genre  \n",
       "count            113999      114000  \n",
       "unique            73608         114  \n",
       "top     Run Rudolph Run    acoustic  \n",
       "freq                151        1000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Observation Count**: The column `track_id` matches the total number of observations (114,000), which indicates every row has a `track_id` entry.\n",
    "\n",
    "2. **Uniqueness**: Despite having 114,000 observations, `track_id` contains only 89,741 unique values. This suggests that some `track_id`s are repeated across multiple rows.\n",
    "\n",
    "4. **track_genre**: This column seems to have very few unique values (only 114), meaning it's highly categorical or repetitive.\n",
    "\n",
    "5. **Frequent Entries**: The `top` values show the most frequent entry for each column, and `freq` gives the count of that value.  \"The Beatles\" is the mode in `artists`; \"Alternative Christmas 2022\"\tis the mode in `album_name`; and \"Run Rudolph Run\" is the mode in `track_name`; and acoustic is the mode in `track_genre`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stablished previously, only one rows contains missing values, amounting to approximmately 0.0001%, of the data which in itself is not very significative.So this missing data is going to be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the Dataframe has 113.999 rows and 20 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113999, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling duplicated values\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated previously the Dataframe has 450 duplicate rows.There are going to be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 20:06:42,285 - INFO - root - The Dataframe without duplicates has 113549 rows and 20 columns\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"The Dataframe without duplicates has {df.shape[0]} rows and {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the duplicated entries in `track_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a `duplicates_id` Dataframe where containing only the rows where the column `track_id` has duplicates and check its dimensions to assert the number of duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 20:06:48,207 - INFO - root - The Dataframe with duplicates has 40108 rows.\n"
     ]
    }
   ],
   "source": [
    "duplicates_id = df[df.duplicated(subset=['track_id'], keep=False)]\n",
    "logging.info(f\"The Dataframe with duplicates has {duplicates_id.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the difference in the number of rows and columns between our original DataFrame (`df`) and the filtered DataFrame of duplicates (`duplicates_id`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 20:06:53,162 - INFO - root - The number of non-duplicated rows is 73441, which is 64.68% of the original Spotify DataFrame.\n"
     ]
    }
   ],
   "source": [
    "difference = (df.shape[0] - duplicates_id.shape[0])\n",
    "\n",
    "# Compute the percentage of non-duplicated rows\n",
    "percentage_non_duplicated = (difference / df.shape[0]) * 100\n",
    "\n",
    "# Print the result\n",
    "logging.info(f\"The number of non-duplicated rows is {difference}, which is {percentage_non_duplicated:.2f}% of the original Spotify DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to check if pairs with duplicated `track_id` along with their respective `track_name` have a correspondence. To ensure that all pairs of duplicated `track_id`s have the same `track_name`, the data is grouped by `track_id` and we check if each group has only one unique `track_name`.\n",
    "\n",
    "1. **`groupby('track_id')`**: Groups the DataFrame by `track_id`.\n",
    "2. **`nunique()`**: Counts the number of unique `track_name` values in each group.\n",
    "3. **Check for inconsistencies**: Identifies `track_id`s where there is more than one unique `track_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 20:06:56,318 - INFO - root - All duplicated track_ids have the same track_name.\n"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby('track_id')['track_name'].nunique()\n",
    "\n",
    "# Check for track_ids with more than one unique track_name\n",
    "inconsistent = grouped[grouped > 1]\n",
    "\n",
    "if inconsistent.empty:\n",
    "    logging.info(\"All duplicated track_ids have the same track_name.\")\n",
    "else:\n",
    "    logging.info(\"Some duplicated track_ids have inconsistent track_names.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all duplicated `track_id`s have the same `track_name`s, we need to further inspect if there is anything that differentiates this duplicate tracks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 20:06:27,023 - INFO - root - No duplicates are fully identical across all fields.\n"
     ]
    }
   ],
   "source": [
    "# Group by 'track_id' and check for identical rows within each group\n",
    "identical_groups = duplicates_id.groupby('track_id').filter(\n",
    "    lambda group: group.drop_duplicates().shape[0] == 1\n",
    ")\n",
    "\n",
    "if identical_groups.empty:\n",
    "    logging.info(\"No duplicates are fully identical across all fields.\")\n",
    "else:\n",
    "    logging.info(\"Fully identical rows:\")\n",
    "    logging.info(identical_groups.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to check the inconsistencies with a function:\n",
    "\n",
    "\n",
    "1. **Identify Duplicates**:\n",
    "   - The code creates a mask to find rows where the specified `id_col` (e.g., `track_id`) has duplicate values. It counts and prints the total number of duplicated rows.\n",
    "\n",
    "2. **Handle No Duplicates**:\n",
    "   - If no duplicates are found, it prints a message and returns an empty DataFrame with columns `id_col` and `inconsistent_columns`.\n",
    "\n",
    "3. **Analyze Inconsistencies**:\n",
    "   - For each unique duplicate identifier (`track_id`), it identifies columns where values differ across rows (`nunique() > 1`).\n",
    "   - It stores details about the inconsistencies, including:\n",
    "     - The identifier (`track_id`).\n",
    "     - The inconsistent columns.\n",
    "     - The number of duplicate entries for the identifier.\n",
    "     - Example values from one of the inconsistent columns.\n",
    "\n",
    "4. **Return Results**:\n",
    "   - If inconsistencies are found, it returns a DataFrame summarizing them.\n",
    "   - If all duplicates are consistent across columns, it prints a message and skips the detailed summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_inconsistencies(df, id_col='track_id'):\n",
    "    \"\"\"\n",
    "    Check for inconsistencies in duplicate records.\n",
    "\n",
    "    This function identifies and analyzes duplicate entries in a DataFrame based on a unique identifier column (`id_col`).\n",
    "    It checks for inconsistencies in other columns and returns a summary of the discrepancies.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to analyze.\n",
    "        id_col (str): The name of the column used to identify duplicates. Defaults to 'track_id'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing details about inconsistencies:\n",
    "            - The identifier (`id_col`) of the duplicates.\n",
    "            - The columns with inconsistent values.\n",
    "            - The number of duplicate entries for each identifier.\n",
    "            - Example inconsistent values for the first flagged column.\n",
    "    \n",
    "    Behavior:\n",
    "        - Prints the total number of duplicate records.\n",
    "        - If no duplicates are found, it prints a message and returns an empty DataFrame.\n",
    "        - If duplicates are consistent across all columns, it prints a message.\n",
    "        - Otherwise, it provides details about the inconsistencies in the duplicates.\n",
    "    \"\"\"\n",
    "\n",
    "    dup_mask = df.duplicated(subset=id_col, keep=False)\n",
    "    logging.info(f\"Total duplicated registers: {dup_mask.sum()}\")\n",
    "    \n",
    "    if not dup_mask.any():\n",
    "        print(\"No duplicates to analyze\")\n",
    "        return pd.DataFrame(columns=[id_col, 'inconsistent_columns'])\n",
    "    \n",
    "    results = []\n",
    "    for track_id in df.loc[dup_mask, id_col].unique():\n",
    "        group = df[df[id_col] == track_id]\n",
    "        inconsistent = [col for col in group.columns \n",
    "                       if col != id_col and group[col].nunique() > 1]\n",
    "        if inconsistent:\n",
    "            results.append({\n",
    "                id_col: track_id,\n",
    "                'inconsistent_columns': ', '.join(inconsistent),\n",
    "                'n_duplicates': len(group),\n",
    "                'example_values': str(group[inconsistent[0]].unique()[:3])  # Muestra primeros valores\n",
    "            })\n",
    "    \n",
    "    if not results:\n",
    "        logging.info(\"Duplicates found but consistent in all columns\")\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `check inconsistencies` function is applies to the `duplicates_id` Dataframe returning an `inconsistencies` Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>inconsistent_columns</th>\n",
       "      <th>n_duplicates</th>\n",
       "      <th>example_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>track_genre</td>\n",
       "      <td>4</td>\n",
       "      <td>['acoustic' 'j-pop' 'singer-songwriter']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>track_genre</td>\n",
       "      <td>2</td>\n",
       "      <td>['acoustic' 'chill']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01MVOl9KtVTNfFiBU9I7dc</td>\n",
       "      <td>track_genre</td>\n",
       "      <td>2</td>\n",
       "      <td>['acoustic' 'indie-pop']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6Vc5wAMmXdKIAM7WUoEb7N</td>\n",
       "      <td>track_genre</td>\n",
       "      <td>2</td>\n",
       "      <td>['acoustic' 'piano']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1EzrEOXmMH3G43AXT1y7pA</td>\n",
       "      <td>track_genre</td>\n",
       "      <td>2</td>\n",
       "      <td>['acoustic' 'rock']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16294</th>\n",
       "      <td>79cxnmnGiC0qZfxi5ogp4j</td>\n",
       "      <td>track_genre</td>\n",
       "      <td>2</td>\n",
       "      <td>['techno' 'trance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16295</th>\n",
       "      <td>1B0FEDRzzN5GP7HGZZfNQl</td>\n",
       "      <td>track_genre</td>\n",
       "      <td>2</td>\n",
       "      <td>['techno' 'trance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16296</th>\n",
       "      <td>4D41idYLHmXYGaHZeRWtPT</td>\n",
       "      <td>track_genre</td>\n",
       "      <td>2</td>\n",
       "      <td>['techno' 'trip-hop']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16297</th>\n",
       "      <td>27nGU2v3syK7aU3AVY2vUO</td>\n",
       "      <td>track_genre</td>\n",
       "      <td>2</td>\n",
       "      <td>['techno' 'trance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16298</th>\n",
       "      <td>2TgTGJyiWf1ptW5g3QG938</td>\n",
       "      <td>track_genre</td>\n",
       "      <td>2</td>\n",
       "      <td>['techno' 'trip-hop']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16299 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     track_id inconsistent_columns  n_duplicates  \\\n",
       "0      5SuOikwiRyPMVoIQDJUgSV          track_genre             4   \n",
       "1      4qPNDBW1i3p13qLCt0Ki3A          track_genre             2   \n",
       "2      01MVOl9KtVTNfFiBU9I7dc          track_genre             2   \n",
       "3      6Vc5wAMmXdKIAM7WUoEb7N          track_genre             2   \n",
       "4      1EzrEOXmMH3G43AXT1y7pA          track_genre             2   \n",
       "...                       ...                  ...           ...   \n",
       "16294  79cxnmnGiC0qZfxi5ogp4j          track_genre             2   \n",
       "16295  1B0FEDRzzN5GP7HGZZfNQl          track_genre             2   \n",
       "16296  4D41idYLHmXYGaHZeRWtPT          track_genre             2   \n",
       "16297  27nGU2v3syK7aU3AVY2vUO          track_genre             2   \n",
       "16298  2TgTGJyiWf1ptW5g3QG938          track_genre             2   \n",
       "\n",
       "                                 example_values  \n",
       "0      ['acoustic' 'j-pop' 'singer-songwriter']  \n",
       "1                          ['acoustic' 'chill']  \n",
       "2                      ['acoustic' 'indie-pop']  \n",
       "3                          ['acoustic' 'piano']  \n",
       "4                           ['acoustic' 'rock']  \n",
       "...                                         ...  \n",
       "16294                       ['techno' 'trance']  \n",
       "16295                       ['techno' 'trance']  \n",
       "16296                     ['techno' 'trip-hop']  \n",
       "16297                       ['techno' 'trance']  \n",
       "16298                     ['techno' 'trip-hop']  \n",
       "\n",
       "[16299 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inconsistencies = check_inconsistencies(duplicates_id)\n",
    "if inconsistencies.empty:\n",
    "    logging.info(\"No inconsistencies found in duplicates\")\n",
    "else:\n",
    "    logging.info(\"Inconsistencies found:\")\n",
    "    display(inconsistencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `inconsistencies` Dataframe the column `inconsistent_columns` contains information about which columns had inconsistencies for each duplicate entry. Through Panda's `.value_counts()` method we are going to count the occurrence of each unique value in the `inconsistent_columns` column to pinpoint wich are the inconsistent column or columns for duplicated tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 20:07:09,375 - INFO - root - inconsistent_columns\n",
      "track_genre                15579\n",
      "popularity, track_genre      720\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "logging.info(inconsistencies['inconsistent_columns'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems only `track_genre` and `popularity` are the inconsistent columns between duplicated tracks. The feature `track_genre` is a qualitative nominal variable indicating the genre in which the track belongs; whereas `popularity` is an int64 value between 0 and 100, indicating the popularity of a track.\n",
    "\n",
    "This entails the that we cannot handle duplicates for `popularity` using the mean, as it's not ideal for integers due to potential floating-point results. The median posses the same problem with even numbered duplicates, with two being the most commen number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 20:07:13,566 - INFO - root - n_duplicates\n",
      "2    11424\n",
      "3     2955\n",
      "4     1361\n",
      "5      431\n",
      "6      104\n",
      "7       21\n",
      "8        2\n",
      "9        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "logging.info(inconsistencies['n_duplicates'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling `popularity` duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case If each value in the duplicates is unique, there is no mode, and attempting to calculate it might result in an error. In such cases, we might need a fallback strategy, such as selecting the median, maximum, or arbitrarily choosing one value (e.g., the first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_popularity(x):\n",
    "    \n",
    "    modes = x.mode()\n",
    "    if len(modes) == 1:  # Single mode\n",
    "        return modes[0]\n",
    "    elif len(modes) > 1:  # Multiple modes (tie)\n",
    "        return max(modes)  # Choose the maximum (or any other criterion)\n",
    "    else:  # No mode\n",
    "        return x.median()  # Fallback to median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy() #copy of the dataset\n",
    "df1['popularity'] = df1.groupby('track_id')['popularity'].transform(resolve_popularity).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling `track_genre` duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acoustic', 'afrobeat', 'alt-rock', 'alternative', 'ambient',\n",
       "       'anime', 'black-metal', 'bluegrass', 'blues', 'brazil',\n",
       "       'breakbeat', 'british', 'cantopop', 'chicago-house', 'children',\n",
       "       'chill', 'classical', 'club', 'comedy', 'country', 'dance',\n",
       "       'dancehall', 'death-metal', 'deep-house', 'detroit-techno',\n",
       "       'disco', 'disney', 'drum-and-bass', 'dub', 'dubstep', 'edm',\n",
       "       'electro', 'electronic', 'emo', 'folk', 'forro', 'french', 'funk',\n",
       "       'garage', 'german', 'gospel', 'goth', 'grindcore', 'groove',\n",
       "       'grunge', 'guitar', 'happy', 'hard-rock', 'hardcore', 'hardstyle',\n",
       "       'heavy-metal', 'hip-hop', 'honky-tonk', 'house', 'idm', 'indian',\n",
       "       'indie', 'indie-pop', 'industrial', 'iranian', 'j-dance', 'j-idol',\n",
       "       'j-pop', 'j-rock', 'jazz', 'k-pop', 'kids', 'latin', 'latino',\n",
       "       'malay', 'mandopop', 'metal', 'metalcore', 'minimal-techno', 'mpb',\n",
       "       'new-age', 'opera', 'pagode', 'party', 'piano', 'pop', 'pop-film',\n",
       "       'power-pop', 'progressive-house', 'psych-rock', 'punk',\n",
       "       'punk-rock', 'r-n-b', 'reggae', 'reggaeton', 'rock', 'rock-n-roll',\n",
       "       'rockabilly', 'romance', 'sad', 'salsa', 'samba', 'sertanejo',\n",
       "       'show-tunes', 'singer-songwriter', 'ska', 'sleep', 'songwriter',\n",
       "       'soul', 'spanish', 'study', 'swedish', 'synth-pop', 'tango',\n",
       "       'techno', 'trance', 'trip-hop', 'turkish', 'world-music'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(df1.track_genre.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To focus on genre solely on sound characteristics, we will remove genres like ‘British’, ‘French’, or ‘German’ from the target variable. These classifications are based on origin or language, which aren’t captured by the audio features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where the condition is True\n",
    "non_sound_based_categories = ['british','brazilian','french','german','iranian','swedish','spanish','indian','malay','turkish','world-music','gospel']\n",
    "df1 = df1.drop(df1[df1['track_genre'].isin(non_sound_based_categories)].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to consolidate genres into major genres and subgenders with a dictionary (this dictionary is the result of a machine learning excercise perfomed on this same dataset by Juan Francisco Leonhardt).It can be found in [Music Genre Classification: A Machine Learning Exercise](https://medium.com/@juanfraleonhardt/music-genre-classification-a-machine-learning-exercise-9c83108fd2bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with descriptive names\n",
    "\n",
    "consolidated_genres = {'agressive-fusion': ['dubstep', 'grunge', 'metal'],\n",
    "                       'industrial': ['goth', 'heavy-metal', 'industrial'],\n",
    "                       'punk-rock': ['alt-rock', 'garage', 'hard-rock', 'j-rock', 'punk', 'punk-rock'],\n",
    "                       'hardstyle': ['happy', 'hardstyle'],\n",
    "                       'disco-ska': ['disco', 'ska', 'synth-pop'],\n",
    "                       'rock': ['alternative', 'rock'],\n",
    "                       'anime': ['anime', 'club'],\n",
    "                       'edm-house': ['deep-house', 'electronic', 'progressive-house'],\n",
    "                       'edm': ['dub', 'edm', 'electro', 'groove', 'house'],\n",
    "                       'j-dance': ['dancehall', 'j-dance'],\n",
    "                       'funk-hip-hop': ['funk', 'hip-hop'],\n",
    "                       'latin': ['dance', 'latin', 'latino', 'reggae', 'reggaeton'],\n",
    "                       'pop': ['k-pop', 'pop', 'pop-film'],\n",
    "                       'brazilian': ['brazil', 'mpb'],\n",
    "                       'blues-rnb': ['blues', 'j-pop', 'r-n-b'],\n",
    "                       'indie': ['folk', 'indie', 'indie-pop', 'psych-rock'],\n",
    "                       'chill': ['chill', 'sad'],\n",
    "                       'pagode-samba': ['pagode', 'samba', 'sertanejo'],\n",
    "                       'country-soul': ['country', 'soul'],\n",
    "                       'rock-n-roll': ['rock-n-roll', 'rockabilly'],\n",
    "                       'chicago-house': ['chicago-house', 'detroit-techno'],\n",
    "                       'jazz-tango': ['honky-tonk', 'jazz', 'tango'],\n",
    "                       'vocal-pop': ['acoustic', 'cantopop', 'mandopop', 'singer-songwriter', 'songwriter'],\n",
    "                       'disney': ['disney', 'guitar'],\n",
    "                       'soundscape': ['ambient', 'new-age']}\n",
    "\n",
    "# Create a dictionary to map old genres to new genres\n",
    "genre_map = {old_genre: new_genre for new_genre, old_genres in consolidated_genres.items() for old_genre in old_genres}\n",
    "\n",
    "# Replace the old genres with the new genres\n",
    "df1['track_genre'] = df1['track_genre'].replace(genre_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining genres are the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 20:08:09,504 - INFO - root - ['afrobeat' 'agressive-fusion' 'anime' 'black-metal' 'bluegrass'\n",
      " 'blues-rnb' 'breakbeat' 'chicago-house' 'children' 'chill' 'classical'\n",
      " 'comedy' 'country-soul' 'death-metal' 'disco-ska' 'disney'\n",
      " 'drum-and-bass' 'edm' 'edm-house' 'emo' 'forro' 'funk-hip-hop'\n",
      " 'grindcore' 'hardcore' 'hardstyle' 'idm' 'indie' 'industrial' 'j-dance'\n",
      " 'j-idol' 'jazz-tango' 'kids' 'latin' 'metalcore' 'minimal-techno' 'opera'\n",
      " 'pagode-samba' 'party' 'piano' 'pop' 'power-pop' 'punk-rock' 'rock'\n",
      " 'rock-n-roll' 'romance' 'salsa' 'show-tunes' 'sleep' 'soundscape' 'study'\n",
      " 'techno' 'trance' 'trip-hop' 'vocal-pop']\n",
      "2025-04-05 20:08:09,511 - INFO - root - Total number of unique values: 54\n"
     ]
    }
   ],
   "source": [
    "logging.info(np.sort(df1.track_genre.unique()))\n",
    "logging.info(f\"Total number of unique values: {df1['track_genre'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `track_genre` we are going to handle duplicates with a function in the following way:\n",
    "\n",
    "\n",
    "1. **Group by `track_id`**:\n",
    "   - Groups rows based on the unique identifier column (`track_id`).\n",
    "\n",
    "2. **Mode Check**:\n",
    "   - Uses `.mode()` to check for the most frequent value in the `track_genre` column.\n",
    "   - If there’s a single mode, it is selected as the resolved genre.\n",
    "\n",
    "3. **Fallback to First**:\n",
    "   - If there’s no mode (or multiple modes in a tie), it defaults to the first genre in the group (`iloc[0]`).\n",
    "\n",
    "4. **Reindexing**:\n",
    "   - Aligns the resolved genres with the original DataFrame indices for proper assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_track_genre(df, id_col='track_id', genre_col='track_genre'):\n",
    "    \"\"\"\n",
    "    Resolves inconsistencies in the `track_genre` column for duplicate entries.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing track data.\n",
    "        id_col (str): The column representing unique identifiers (e.g., 'track_id').\n",
    "        genre_col (str): The column containing track genres (e.g., 'track_genre').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with consistent `track_genre` for each `track_id`,\n",
    "                      choosing the mode if it exists, or the first genre otherwise.\n",
    "    \"\"\"\n",
    "    def resolve_genre(group):\n",
    "        # Check if there is a mode\n",
    "        modes = group[genre_col].mode()  # Returns a Series of modes\n",
    "        if len(modes) == 1:\n",
    "            # If there's one clear mode, return it\n",
    "            return modes.iloc[0]\n",
    "        else:\n",
    "            # If there's no mode or multiple modes, return the first genre\n",
    "            return group[genre_col].iloc[0]\n",
    "\n",
    "    # Create a new column to store resolved genres\n",
    "    resolved_genres = df.groupby(id_col).apply(\n",
    "        lambda group: resolve_genre(group)\n",
    "    )\n",
    "\n",
    "    # Map the resolved genres back to the original DataFrame\n",
    "    df[genre_col] = df[id_col].map(resolved_genres)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76688/827728963.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  resolved_genres = df.groupby(id_col).apply(\n"
     ]
    }
   ],
   "source": [
    "# Resolve track_genre inconsistencies\n",
    "df2 = df1.copy()\n",
    "df2 = resolve_track_genre(df2, id_col='track_id', genre_col='track_genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final number of genres is 54."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 20:08:29,790 - INFO - root - ['afrobeat' 'agressive-fusion' 'anime' 'black-metal' 'bluegrass'\n",
      " 'blues-rnb' 'breakbeat' 'chicago-house' 'children' 'chill' 'classical'\n",
      " 'comedy' 'country-soul' 'death-metal' 'disco-ska' 'disney'\n",
      " 'drum-and-bass' 'edm' 'edm-house' 'emo' 'forro' 'funk-hip-hop'\n",
      " 'grindcore' 'hardcore' 'hardstyle' 'idm' 'indie' 'industrial' 'j-dance'\n",
      " 'j-idol' 'jazz-tango' 'kids' 'latin' 'metalcore' 'minimal-techno' 'opera'\n",
      " 'pagode-samba' 'party' 'piano' 'pop' 'power-pop' 'punk-rock' 'rock'\n",
      " 'rock-n-roll' 'romance' 'salsa' 'show-tunes' 'sleep' 'soundscape' 'study'\n",
      " 'techno' 'trance' 'trip-hop' 'vocal-pop']\n",
      "2025-04-05 20:08:29,797 - INFO - root - Total number of unique values: 54\n"
     ]
    }
   ],
   "source": [
    "logging.info(np.sort(df2.track_genre.unique()))\n",
    "logging.info(f\"Total number of unique values: {df2['track_genre'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions for handling these columns only modify the data but do not remove duplicate rows automatically, so we need to verify and clean up duplicates explicitly.Bearing in mind this we verify the duplicates rows in `df2` are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 20:10:29,532 - INFO - root - Fully identical rows:\n",
      "2025-04-05 20:10:29,533 - INFO - root - 100606\n"
     ]
    }
   ],
   "source": [
    "# Group by 'track_id' and check for identical rows within each group\n",
    "identical_groups = df2.groupby('track_id').filter(\n",
    "    lambda group: group.drop_duplicates().shape[0] == 1\n",
    ")\n",
    "\n",
    "if identical_groups.empty:\n",
    "    logging.info(\"No duplicates are fully identical across all fields.\")\n",
    "else:\n",
    "    logging.info(\"Fully identical rows:\")\n",
    "    logging.info(identical_groups.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have verified it, we are going to drop the duplicates.We keep the first occurrence as the inconsistencies where already handled and duplicates rows contain the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop_duplicates(subset='track_id', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify the new dimensions of the `df2` Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 20:10:35,294 - INFO - root - The new dimensions of the Dataframe after handling and dropping duplicates are 80081 rows and 20 columns.\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"The new dimensions of the Dataframe after handling and dropping duplicates are {df2.shape[0]} rows and {df2.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Transforming `duration_ms` into minutes for readability\n",
    " ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert `durantion_ms` into minutes in a new column `minutes` for better understanding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert milliseconds to minutes\n",
    "df2['minutes'] = (df2['duration_ms'] // 60000)  # Divide by 60000 to get minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might return floats instead of integers, so we have to ensure they are treated as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['minutes'] = df2['duration_ms'].astype(float) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming `mode`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0. We are going to verify if the data of this feature is boolean and if its values are \"0\" and \"1\". The result is that its values are indeed \"0\" and \"1\", but its data type is int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 20:14:55,737 - INFO - root - Number of unique values: 2\n",
      "2025-04-05 20:14:55,738 - INFO - root - Unique values: [0 1]\n",
      "2025-04-05 20:14:55,740 - INFO - root - Data type:int64\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"Number of unique values: {df2['mode'].nunique()}\")\n",
    "logging.info(f\"Unique values: {df2['mode'].unique()}\")\n",
    "logging.info(f\"Data type:{df2['mode'].dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to transformn this feature into a nominal feature for better undersatanding, mapping the ceros to \"minor\" and the ones to \"major\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['mode_nominal'] = df2['mode'].map({0: 'minor', 1: 'major'}).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 20:30:48,958 - INFO - root - Number of unique values: 2\n",
      "2025-04-05 20:30:48,972 - INFO - root - Unique values: ['minor' 'major']\n",
      "2025-04-05 20:30:48,975 - INFO - root - Data type:object\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"Number of unique values: {df2['mode_nominal'].nunique()}\")\n",
    "logging.info(f\"Unique values: {df2['mode_nominal'].unique()}\")\n",
    "logging.info(f\"Data type:{df2['mode_nominal'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming `key`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key the track is in. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1. We are going to verify if the data of this feature is int64 and if its values correspsond to the documented ones. The result is that its values are indeed int64 and numerical, and all keys are present (there are 12 chromatical `key`s), and no tracks without key detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 20:26:50,727 - INFO - root - Number of unique values: 12\n",
      "2025-04-05 20:26:50,730 - INFO - root - Unique values: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "2025-04-05 20:26:50,732 - INFO - root - Data type:int64\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"Number of unique values: {df2['key'].nunique()}\")\n",
    "logging.info(f\"Unique values: {np.sort(df2.key.unique())}\") \n",
    "logging.info(f\"Data type:{df2['key'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to transform this values into nominal ones for better understanding. This in done thrhough mapping and a dictionary constructed based on the documentation for this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping dictionary for keys\n",
    "key_mapping = {\n",
    "    -1: 'No Key Detected',\n",
    "    0: 'C',\n",
    "    1: 'C♯/D♭',\n",
    "    2: 'D',\n",
    "    3: 'D♯/E♭',\n",
    "    4: 'E',\n",
    "    5: 'F',\n",
    "    6: 'F♯/G♭',\n",
    "    7: 'G',\n",
    "    8: 'G♯/A♭',\n",
    "    9: 'A',\n",
    "    10: 'A♯/B♭',\n",
    "    11: 'B'\n",
    "}\n",
    "\n",
    "# Map the 'key' column to its corresponding pitch notation\n",
    "df2['key_nominal'] = df2['key'].map(key_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 20:29:55,473 - INFO - root - Number of unique values: 12\n",
      "2025-04-05 20:29:55,485 - INFO - root - Unique values: ['A' 'A♯/B♭' 'B' 'C' 'C♯/D♭' 'D' 'D♯/E♭' 'E' 'F' 'F♯/G♭' 'G' 'G♯/A♭']\n",
      "2025-04-05 20:29:55,488 - INFO - root - Data type:object\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"Number of unique values: {df2['key_nominal'].nunique()}\")\n",
    "logging.info(f\"Unique values: {np.sort(df2.key_nominal.unique())}\") \n",
    "logging.info(f\"Data type:{df2['key_nominal'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes_counts = df2['minutes'].value_counts()\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(12, 6))  # Set the size of the plot\n",
    "sns.barplot(x=minutes_counts.index, y=minutes_counts.values, palette=\"magma\", dodge=False)\n",
    "\n",
    "#Add labels and titleñ\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "plt.xlabel(\"Track duration (minutes)\")  # Label for x-axis\n",
    "plt.ylabel(\"Count\")  # Label for y-axis\n",
    "plt.title(\"Distribution of Track Duration in Minutes\")  # Title for the plot\n",
    "plt.tight_layout()  # Adjust layout for better fit\n",
    "\n",
    "# Step 4: Display the plot\n",
    "plt.show()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
